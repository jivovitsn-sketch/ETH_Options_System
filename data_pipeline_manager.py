#!/usr/bin/env python3
import schedule
import time
import subprocess
import logging
from datetime import datetime
import sqlite3
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('./logs/data_pipeline.log'),
        logging.StreamHandler()
    ]
)

class DataPipelineManager:
    def __init__(self):
        self.scripts = {
            'futures': {
                'script': './futures_data_monitor.py',
                'interval_minutes': 1,
                'last_run': None,
                'timeout': 30
            },
            'liquidations': {
                'script': './liquidations_monitor.py', 
                'interval_minutes': 1,
                'last_run': None,
                'timeout': 30
            },
            'gamma': {
                'script': './gamma_exposure_calculator.py',
                'interval_minutes': 5,
                'last_run': None, 
                'timeout': 60
            },
            'funding': {
                'script': './funding_rate_monitor.py',
                'interval_minutes': 5,
                'last_run': None,
                'timeout': 30
            }
        }
        
    def run_script(self, script_name, script_config):
        """–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ —Å –∫–æ–Ω—Ç—Ä–æ–ª–µ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –æ—à–∏–±–æ–∫"""
        try:
            logging.info(f"–ó–∞–ø—É—Å–∫ {script_name}...")
            result = subprocess.run(
                ['python3', script_config['script']],
                timeout=script_config['timeout'],
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                logging.info(f"{script_name} —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω")
                script_config['last_run'] = datetime.now()
                return True
            else:
                logging.error(f"–û—à–∏–±–∫–∞ –≤ {script_name}: {result.stderr}")
                self.send_alert(f"üö® –°–ë–û–ô {script_name}: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logging.error(f"–¢–∞–π–º–∞—É—Ç {script_name} (> {script_config['timeout']} —Å–µ–∫)")
            self.send_alert(f"‚è∞ –¢–ê–ô–ú–ê–£–¢ {script_name}")
            return False
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ {script_name}: {e}")
            self.send_alert(f"üö® –û–®–ò–ë–ö–ê {script_name}: {e}")
            return False
    
    def send_alert(self, message):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –∞–ª–µ—Ä—Ç–∞ –≤ Telegram"""
        try:
            from telegram_helper import send_telegram_message
            send_telegram_message(message, is_alert=True)
        except Exception as e:
            logging.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∞–ª–µ—Ä—Ç: {e}")
    
    def check_data_freshness(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            conn = sqlite3.connect('./data/futures_data.db')
            cursor = conn.cursor()
            
            tables_to_check = ['futures_ticker', 'liquidations', 'orderbook_snapshots']
            current_time = datetime.now().timestamp()
            max_age_threshold = 300  # 5 –º–∏–Ω—É—Ç
            
            alerts = []
            for table in tables_to_check:
                cursor.execute(f"SELECT MAX(timestamp) FROM {table}")
                result = cursor.fetchone()
                if result and result[0]:
                    data_age = current_time - result[0]
                    if data_age > max_age_threshold:
                        alerts.append(f"üìä –î–∞–Ω–Ω—ã–µ –≤ {table} —É—Å—Ç–∞—Ä–µ–ª–∏: {data_age/60:.1f} –º–∏–Ω –Ω–∞–∑–∞–¥")
            
            conn.close()
            
            if alerts:
                self.send_alert("üö® –ü–†–û–í–ï–†–ö–ê –°–í–ï–ñ–ï–°–¢–ò –î–ê–ù–ù–´–•:\\n" + "\\n".join(alerts))
                
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≤–µ–∂–µ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def backup_databases(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±—ç–∫–∞–ø–æ–≤ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            backup_dir = f"./backups/{timestamp}"
            os.makedirs(backup_dir, exist_ok=True)
            
            databases = [
                './data/futures_data.db',
                './data/funding_alerts.db', 
                './data/oi_signals.db'
            ]
            
            for db_path in databases:
                if os.path.exists(db_path):
                    backup_path = f"{backup_dir}/{os.path.basename(db_path)}"
                    subprocess.run(['cp', db_path, backup_path])
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 10)
            backups = sorted([d for d in os.listdir('./backups') if os.path.isdir(f'./backups/{d}')])
            if len(backups) > 10:
                for old_backup in backups[:-10]:
                    subprocess.run(['rm', '-rf', f'./backups/{old_backup}'])
                    
            logging.info(f"–°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø: {backup_dir}")
            
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –±—ç–∫–∞–ø–∞: {e}")
    
    def start(self):
        """–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        logging.info("üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã–º–∏...")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —Å–∫—Ä–∏–ø—Ç—ã —Å—Ä–∞–∑—É –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        for name, config in self.scripts.items():
            self.run_script(name, config)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ
        schedule.every(1).minutes.do(lambda: self.run_script('futures', self.scripts['futures']))
        schedule.every(1).minutes.do(lambda: self.run_script('liquidations', self.scripts['liquidations']))
        schedule.every(5).minutes.do(lambda: self.run_script('gamma', self.scripts['gamma']))
        schedule.every(5).minutes.do(lambda: self.run_script('funding', self.scripts['funding']))
        schedule.every(10).minutes.do(self.check_data_freshness)
        schedule.every(6).hours.do(self.backup_databases)
        
        logging.info("üìÖ –†–∞—Å–ø–∏—Å–∞–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ. –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞...")
        
        while True:
            schedule.run_pending()
            time.sleep(1)

if __name__ == "__main__":
    manager = DataPipelineManager()
    manager.start()
