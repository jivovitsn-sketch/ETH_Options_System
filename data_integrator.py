#!/usr/bin/env python3
"""
Data Integrator v2 - —Ä–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ —Å–∏—Å—Ç–µ–º—ã
"""

import os
import json
import logging
import glob
from datetime import datetime
from typing import Dict, Any, List

class DataIntegrator:
    def __init__(self):
        self.logger = logging.getLogger('DataIntegrator')
        self.base_data_dir = 'data'
        
        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –º–µ–∂–¥—É —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –ø–∞–ø–∫–∞–º–∏
        self.data_mapping = {
            'funding': 'funding_rate',
            'liquidations': 'liquidations',
            'futures': 'futures_oi', 
            'pcr': 'pcr',
            'oi': 'oi',
            'max_pain': 'max_pain',
            'gex': 'gamma_exposure',
            'vanna': 'vanna',
            'iv_rank': 'iv_rank',
            'volatility': 'volatility_greeks'
        }
    
    def _get_latest_file(self, directory: str, asset: str, pattern: str = None) -> str:
        """–ù–∞–π—Ç–∏ —Å–∞–º—ã–π —Å–≤–µ–∂–∏–π —Ñ–∞–π–ª –¥–ª—è –∞–∫—Ç–∏–≤–∞ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏"""
        if not os.path.exists(directory):
            return None
            
        if pattern:
            search_pattern = f"{directory}/{asset}_{pattern}*.json"
        else:
            search_pattern = f"{directory}/{asset}_*.json"
        
        files = glob.glob(search_pattern)
        if not files:
            return None
            
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π —Ñ–∞–π–ª (–ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è)
        return max(files, key=os.path.getmtime)
    
    def _load_latest_data(self, data_type: str, asset: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–∞–º—ã–µ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–∏–ø–∞ –∏ –∞–∫—Ç–∏–≤–∞"""
        directory_key = self.data_mapping.get(data_type)
        if not directory_key:
            self.logger.warning(f"Unknown data type: {data_type}")
            return {}
            
        directory = os.path.join(self.base_data_dir, directory_key)
        latest_file = self._get_latest_file(directory, asset)
        
        if not latest_file:
            self.logger.debug(f"No data found for {asset} in {directory}")
            return {}
        
        try:
            with open(latest_file, 'r') as f:
                data = json.load(f)
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ —Ñ–∞–π–ª–µ
                data['_metadata'] = {
                    'file_path': latest_file,
                    'file_timestamp': datetime.fromtimestamp(os.path.getmtime(latest_file)).isoformat(),
                    'data_type': data_type
                }
                return data
        except Exception as e:
            self.logger.error(f"Error loading {latest_file}: {e}")
            return {}
    
    def get_futures_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('futures', asset)
    
    def get_funding_rate(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('funding', asset)
    
    def get_liquidations(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('liquidations', asset)
    
    def get_pcr_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('pcr', asset)
    
    def get_oi_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('oi', asset)
    
    def get_max_pain(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('max_pain', asset)
    
    def get_gamma_exposure(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('gex', asset)
    
    def get_vanna_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('vanna', asset)
    
    def get_iv_rank_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('iv_rank', asset)
    
    def get_volatility_data(self, asset: str) -> Dict[str, Any]:
        return self._load_latest_data('volatility', asset)
    
    def _calculate_data_quality(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∂–µ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        available_sources = 0
        meta_fields = ['timestamp', 'asset', 'data_quality', '_metadata']
        data_fields = [k for k in data.keys() if k not in meta_fields]
        total_sources = len(data_fields)
        
        for key in data_fields:
            if data[key] and isinstance(data[key], dict) and len(data[key]) > 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –Ω–µ-–º–µ—Ç–∞ –ø–æ–ª–µ
                non_meta_fields = [k for k in data[key].keys() if not k.startswith('_')]
                if non_meta_fields:
                    available_sources += 1
        
        quality_score = available_sources / total_sources if total_sources > 0 else 0
        
        return {
            'available_sources': available_sources,
            'total_sources': total_sources,
            'quality_score': round(quality_score, 2),
            'timestamp': datetime.now().isoformat()
        }
    
    def get_all_data(self, asset: str) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –í–°–ï –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–∫—Ç–∏–≤–∞"""
        self.logger.info(f"Integrating data for {asset}")
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        data = {
            # –§—å—é—á–µ—Ä—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            'futures': self.get_futures_data(asset),
            'funding': self.get_funding_rate(asset),
            'liquidations': self.get_liquidations(asset),
            
            # –û–ø—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            'pcr': self.get_pcr_data(asset),
            'oi': self.get_oi_data(asset),
            'max_pain': self.get_max_pain(asset),
            'gex': self.get_gamma_exposure(asset),
            'vanna': self.get_vanna_data(asset),
            'iv_rank': self.get_iv_rank_data(asset),
            'volatility': self.get_volatility_data(asset),
            
            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            'timestamp': datetime.now().isoformat(),
            'asset': asset
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        data['data_quality'] = self._calculate_data_quality(data)
        
        return data
    
    def get_available_assets(self) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–æ–≤, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ"""
        assets = set()
        
        for data_type, directory in self.data_mapping.items():
            dir_path = os.path.join(self.base_data_dir, directory)
            if os.path.exists(dir_path):
                files = glob.glob(f"{dir_path}/*.json")
                for file in files:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –∞–∫—Ç–∏–≤–∞ –∏–∑Êñá‰ª∂Âêç (–ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å –¥–æ _)
                    filename = os.path.basename(file)
                    asset = filename.split('_')[0]
                    assets.add(asset)
        
        return sorted(list(assets))

# –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    integrator = DataIntegrator()
    
    print("üß™ DataIntegrator v2 - –¢–ï–°–¢ –° –†–ï–ê–õ–¨–ù–´–ú–ò –î–ê–ù–ù–´–ú–ò")
    print("=" * 50)
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∞–∫—Ç–∏–≤—ã
    available_assets = integrator.get_available_assets()
    print(f"üìä –ù–∞–π–¥–µ–Ω—ã –∞–∫—Ç–∏–≤—ã: {available_assets}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –∫–∞–∂–¥–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–º –∞–∫—Ç–∏–≤–µ
    for asset in available_assets[:3]:  # –ü–µ—Ä–≤—ã–µ 3 —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å
        print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É–µ–º {asset}...")
        try:
            data = integrator.get_all_data(asset)
            quality = data['data_quality']
            print(f"   ‚úÖ {asset}: {quality['available_sources']}/{quality['total_sources']} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (–∫–∞—á–µ—Å—Ç–≤–æ: {quality['quality_score']})")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã
            found_sources = []
            for key, value in data.items():
                if key not in ['timestamp', 'asset', 'data_quality'] and value and len(value) > 0:
                    non_meta_fields = [k for k in value.keys() if not k.startswith('_')]
                    if non_meta_fields:
                        found_sources.append(key)
            
            if found_sources:
                print(f"   üìÅ –ù–∞–π–¥–µ–Ω—ã: {', '.join(found_sources)}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –¥–ª—è {asset}: {e}")
    
    print("\n" + "=" * 50)
    print("üéâ DataIntegrator v2 –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
